{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eacf5526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "563450aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0df9fd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the train dataset\n",
    "data = pd.read_csv('train.csv')\n",
    "# data = data.sample(frac=0.02,random_state=200)\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "011866da",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Unique Numbers : [1 0 4 7 3 5 8 9 2 6]\nNumber of classes : 10\n"
     ]
    }
   ],
   "source": [
    "#checking unique numbers in train label column\n",
    "unique = data['label'].unique()\n",
    "print(\"Unique Numbers :\",unique)\n",
    "\n",
    "#countine the unique number of digits for classification\n",
    "n_classes = len(unique)\n",
    "print(\"Number of classes :\",n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea886d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering the dataset between X and Y\n",
    "x = data.drop(labels = [\"label\"], axis=1)\n",
    "y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a26a4166",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(33600, 784) (8400, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.20, random_state=42,stratify=y)\n",
    "# # normalize pixel values\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "print(x_train.to_numpy().shape,x_test.to_numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89eb32ad",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "k1: [[-8.89511116e-03  5.23336366e-03 -1.06932397e-02  4.45728397e-03\n",
      "   2.40355181e-03 -6.47764860e-03  1.61557570e-02 -8.36140787e-03\n",
      "   3.93018427e-03  2.65778104e-03  1.65130032e-02 -1.40250756e-02\n",
      "  -7.78692808e-03 -2.49844081e-03 -1.35254267e-02  1.17857602e-02\n",
      "  -1.19012881e-02 -1.08443549e-02 -1.03810918e-02 -5.35125753e-03\n",
      "  -3.03736657e-03 -1.75693757e-02  7.16726656e-03  3.23883787e-03\n",
      "  -1.23913747e-02 -1.31945539e-02 -2.66297025e-03 -6.17728942e-03\n",
      "   4.02523652e-03  4.54587586e-03 -8.81859873e-03  2.49729689e-03\n",
      "  -2.53572375e-03  1.42688061e-02  3.61927406e-03 -1.35686904e-02\n",
      "   5.87167946e-03  1.28451383e-02 -7.14959694e-03  1.86209698e-02\n",
      "   5.69586787e-03  1.24582834e-02 -1.93124172e-02 -1.63984369e-02\n",
      "  -2.25886928e-02 -3.43417686e-04 -1.28105925e-02 -1.36801464e-02\n",
      "   1.83247466e-02  1.75360617e-03 -7.55248243e-04  2.38260087e-03\n",
      "   2.38183490e-03 -2.22188468e-02  1.56832260e-02  2.33213568e-02\n",
      "   9.25650366e-03  4.20507014e-03  2.75839551e-03 -1.21955049e-02\n",
      "  -7.15604820e-04 -8.10848540e-03 -1.05089764e-02  3.23137335e-03\n",
      "   1.43649257e-02  2.40765115e-02  4.84872516e-03 -1.76591755e-02\n",
      "  -1.51158603e-02  3.03211781e-03 -7.46536579e-03 -1.97492955e-03\n",
      "   1.59303309e-02 -8.19147647e-03  6.36733894e-03 -2.19693616e-02\n",
      "   1.13093680e-02  7.63249289e-03  7.68818943e-03  1.19961447e-02\n",
      "   9.06134231e-03 -9.30968277e-03 -1.34663325e-02 -1.09030771e-02\n",
      "  -9.66955195e-03  1.61672843e-02  7.41892481e-03 -8.15682456e-03\n",
      "   7.15238274e-03  9.58339851e-04  1.91858056e-03 -3.02777803e-03\n",
      "   1.75086979e-02  3.95696788e-04  4.19549727e-03 -2.25430234e-03\n",
      "   1.39740704e-02  9.39390786e-03  1.01543807e-02  6.33204189e-03\n",
      "   6.00370362e-03  1.96603385e-03  1.70944952e-03 -1.51641330e-02\n",
      "  -1.12592366e-03 -5.19595599e-03 -6.03612376e-03  4.06493420e-06\n",
      "   7.54610840e-03 -2.83321612e-04 -6.91568640e-04  1.09474562e-02\n",
      "   5.26719741e-03  1.98802759e-02  1.24570256e-02 -1.07768067e-02\n",
      "   2.01185761e-03 -1.21755475e-03  4.67316358e-04  1.19733037e-02\n",
      "   9.70109009e-03 -9.34488033e-03  1.08525175e-02 -5.01169143e-03\n",
      "  -4.83218053e-03  2.98526095e-03 -1.04727753e-02 -2.96073264e-02\n",
      "  -1.56817752e-02 -1.14457624e-02  2.74381107e-03  1.13505961e-02\n",
      "  -2.60202408e-03  6.31135478e-03  1.19785690e-02 -2.56688076e-03\n",
      "   5.27772917e-03  1.08165965e-02  9.86979299e-03 -2.74097344e-03\n",
      "   1.04174497e-02 -1.45375884e-02  4.08572759e-03 -1.66847280e-03\n",
      "   6.33231911e-03 -2.24521057e-02 -1.26849001e-02  7.24371188e-03\n",
      "  -2.30824481e-02  1.19558773e-03 -1.33690591e-02 -8.09050769e-03\n",
      "  -1.45200620e-03 -2.42566446e-03  7.98203303e-03  1.43322956e-03\n",
      "  -9.94226319e-03  7.73055985e-03 -2.83090561e-03  1.03635446e-02\n",
      "  -7.01668997e-03 -3.84740652e-03 -4.80866379e-03  1.13952505e-02\n",
      "  -4.10252251e-03  3.16981449e-03  1.77701103e-02 -4.48559370e-03\n",
      "   4.98724029e-03  8.87891448e-03  8.47892958e-03 -1.20231427e-02\n",
      "   3.91215506e-03  3.25572274e-03 -1.31131361e-03 -6.25613137e-04\n",
      "  -7.60704251e-03 -7.74489084e-03  1.89638924e-04  1.22322313e-03\n",
      "   1.35616924e-02 -1.04930709e-03  3.19080115e-03  9.54804581e-03\n",
      "   6.56582194e-03 -1.00028547e-02  6.96094147e-03 -1.26723664e-02\n",
      "  -1.32733857e-02 -8.04100058e-03  2.23801243e-02  3.02036846e-03\n",
      "   4.59723534e-03 -2.33661949e-04 -1.98136673e-03  5.07641032e-03\n",
      "  -3.70544999e-03 -1.02285838e-03  5.73208806e-03 -5.33248578e-04\n",
      "   8.70175943e-03 -2.47254125e-03 -1.46071274e-02 -1.79171534e-03\n",
      "  -3.13442168e-03  8.69616388e-03 -3.84978200e-03  5.17008747e-03\n",
      "  -5.99173539e-03  2.13492393e-02 -8.59206343e-03 -7.82467286e-04\n",
      "   5.07644191e-04  4.98214897e-03 -7.18083327e-03 -1.25202640e-02\n",
      "   3.62908143e-03  1.03571548e-02  7.72397367e-03  1.11606651e-02\n",
      "   5.71049128e-03  1.28907515e-02  7.55597787e-03  4.45904893e-03\n",
      "  -7.65650128e-03  7.24669441e-03 -1.82370328e-02 -3.06267801e-03\n",
      "   5.79973547e-03  3.84547868e-03 -5.37448170e-03 -1.26223073e-02\n",
      "  -8.66729746e-03 -9.12897490e-03 -2.74731309e-02 -7.88649890e-03\n",
      "   1.24172016e-02  5.31088226e-03 -3.41651474e-03  4.65601897e-04\n",
      "   1.98273158e-03 -1.04134576e-02 -9.04576826e-03 -5.87737284e-03\n",
      "   6.29699943e-03  5.09148078e-03  1.41383566e-02  1.79095897e-03\n",
      "  -1.81019558e-04 -2.88148155e-03  3.08573545e-03 -7.67778309e-03\n",
      "   6.79984782e-03  1.65192577e-02 -1.80361682e-02  1.42005547e-02\n",
      "  -7.16269926e-03 -5.51251518e-03  5.64859347e-04  1.74359367e-02\n",
      "  -6.52199465e-03 -1.20400135e-02 -9.88740562e-03  3.21242105e-03\n",
      "   2.13821429e-02  1.06464029e-02 -1.29721246e-02 -1.33097979e-02\n",
      "   5.96272246e-03  8.59386670e-03 -5.16286059e-03  5.56776408e-04\n",
      "   3.88011938e-03 -1.17075963e-03 -9.18008976e-04 -2.48442318e-03\n",
      "  -4.40127203e-03  1.57380448e-02 -1.10656405e-02  1.71200772e-02\n",
      "   3.14449323e-03  7.99100444e-03 -1.69467137e-03  1.44071719e-02\n",
      "   1.68891963e-03 -1.12047315e-02 -1.32838632e-02  7.72002299e-04\n",
      "   8.76852322e-03 -7.77511507e-03 -1.89750294e-03  8.04659501e-03\n",
      "  -5.19449140e-03  1.00421711e-02 -8.72927006e-03 -2.23461038e-03\n",
      "   7.13785593e-03  1.39993687e-02  1.27123151e-02  1.18686159e-04\n",
      "   1.18144606e-02  3.64873793e-03 -1.83337778e-02  1.07958593e-02\n",
      "  -7.83989691e-03 -1.02551152e-02 -4.34451861e-03  8.00347788e-03\n",
      "  -3.40948774e-03  3.79812729e-03  2.28670098e-02 -5.65403485e-03\n",
      "  -6.91700069e-03 -2.03382350e-02 -1.01863727e-02  1.75348229e-02\n",
      "  -1.86601977e-02  1.50641661e-02 -7.39616141e-03  7.66100637e-03\n",
      "  -5.62525756e-04  8.14031091e-03 -2.19482959e-02 -6.00144549e-03\n",
      "   1.92911187e-02  6.49204083e-03  1.93684350e-02  3.25927115e-04\n",
      "   1.82350358e-02 -8.15140681e-03 -1.21362588e-03  7.16805664e-03\n",
      "   1.12811019e-02 -4.43969894e-03 -4.62156771e-03  2.60985095e-02\n",
      "  -1.31297141e-02 -6.94341945e-03 -1.80107801e-03  3.02394061e-03\n",
      "  -1.29678735e-02  6.03474902e-03 -6.80099874e-03  4.14127899e-03\n",
      "  -1.49741936e-02 -1.10653592e-02  2.57579363e-03  5.15500176e-03\n",
      "  -1.35341184e-02  5.60602160e-03 -7.15578761e-03 -8.25908246e-03\n",
      "  -1.05388397e-02 -1.68921942e-02 -5.63671059e-03 -4.04101708e-03\n",
      "  -1.24702569e-02  4.01087851e-03 -1.62785919e-03 -1.92106399e-02\n",
      "   1.13953886e-02 -9.52425159e-03  5.67797158e-03  5.40717237e-03\n",
      "  -1.40898510e-03  1.54479450e-02  1.25969881e-02  6.29755131e-03\n",
      "  -5.08560437e-03 -2.54015268e-02 -9.00780009e-03 -1.36572938e-02\n",
      "   1.86625860e-03  7.55857787e-03  1.91590684e-03 -1.01766628e-02\n",
      "   1.08852640e-02  1.41969326e-02  5.08454781e-03 -4.26965262e-03\n",
      "  -1.06494721e-02 -5.46068358e-03  6.35812964e-03  2.90119069e-03\n",
      "  -4.45958491e-03 -2.34459017e-03  1.67998154e-02  2.21481048e-02\n",
      "  -1.41290197e-02 -4.91341935e-03 -1.54749141e-02 -1.38478803e-02]] k0: [[ 5.83005893e-03  3.23183036e-03  5.44944959e-03  1.09796688e-02\n",
      "  -5.25715407e-03  8.85675037e-03  1.17514061e-02 -1.15689174e-03\n",
      "  -7.03269298e-03  6.26382674e-04 -2.77301846e-03 -2.46960145e-02\n",
      "  -1.30901527e-02 -9.33183023e-03 -5.21828940e-04  1.02510445e-02\n",
      "   3.01922747e-03  3.88030315e-04 -2.40088605e-03  4.33532531e-03\n",
      "   2.53690327e-03 -6.44060212e-03  9.05245797e-03 -7.96050010e-03\n",
      "  -9.92626031e-05 -7.06918395e-03 -1.47850646e-02 -9.02722003e-03\n",
      "   5.49009554e-03 -5.46541836e-03 -2.11249704e-03  2.97976538e-03\n",
      "   1.44385680e-02 -1.89259743e-02 -1.56361465e-02  1.47960405e-02\n",
      "  -9.73097726e-04  4.71318305e-03 -1.58741591e-03  5.63348531e-03\n",
      "   1.72235792e-02 -6.58479375e-03 -5.23572523e-03  7.64249181e-03\n",
      "  -5.48560216e-03 -1.41992121e-02  1.31608375e-02 -3.74154123e-03\n",
      "  -2.00313218e-02  1.10926710e-02 -1.62456220e-03 -3.94959913e-04\n",
      "  -3.62099105e-03  1.66044848e-02 -9.63447828e-03 -8.98492686e-03\n",
      "   1.19485784e-02  7.00691211e-03 -5.06088368e-04 -1.18230777e-02\n",
      "   5.31217677e-03 -3.71435384e-03  1.72244601e-02  4.80180465e-03\n",
      "   1.67805718e-02 -7.27725262e-03  1.86009889e-02  1.74964945e-02\n",
      "  -1.23870587e-03  3.15952917e-04  4.12522299e-04  1.59440329e-03\n",
      "  -6.24050986e-04  3.80497876e-02 -3.26209293e-03 -8.52367505e-03\n",
      "  -3.08164248e-04  8.27999687e-03  5.43381883e-03 -2.39725833e-03\n",
      "  -2.20106903e-03 -1.81219711e-04 -4.59861700e-03  1.06242227e-02\n",
      "  -5.02019703e-03 -1.30216314e-02  4.25563515e-03 -8.45900899e-03\n",
      "   7.10481393e-03 -1.82496867e-02  5.78454810e-03  1.83016869e-03\n",
      "   6.81277868e-03  3.94473801e-03  4.32794816e-03 -1.51269306e-02\n",
      "   1.37247938e-02 -1.52180351e-04 -1.28399451e-03 -5.36084246e-03\n",
      "   1.17594756e-02  2.42222421e-03  1.12743506e-03  8.37474120e-03\n",
      "   3.46019591e-03  6.90151262e-03 -1.47893999e-02  1.24395447e-02\n",
      "   6.27853697e-03  8.42406917e-03  1.61056219e-03  8.58525078e-03\n",
      "   1.62478488e-02 -1.39360772e-03 -2.43835572e-03 -4.35008651e-03\n",
      "  -1.24424361e-02 -1.14936458e-02  7.60720076e-03 -2.63680021e-03\n",
      "  -1.14111798e-02 -2.64758803e-02 -3.96745031e-03  7.93994595e-03\n",
      "   7.22564857e-03  8.67521862e-03 -1.52062088e-02 -8.45700743e-03\n",
      "   3.67634680e-03  5.36384656e-03 -3.13832809e-03 -6.04222603e-03\n",
      "  -1.73225116e-02 -1.99833992e-03  1.03457239e-02 -2.34631518e-03\n",
      "   9.29288276e-03 -4.70022737e-04 -3.53880342e-03 -8.23335252e-03\n",
      "  -9.21170246e-03  3.17860317e-03  1.15582270e-02  1.39581358e-02\n",
      "   3.85653914e-03  8.83962452e-03  5.82699141e-03  7.80415332e-04\n",
      "  -1.61652562e-02 -5.96314448e-03 -3.67795654e-03 -3.30038177e-03\n",
      "  -1.36853223e-02 -5.57396461e-03 -1.65995898e-02  8.60574538e-03\n",
      "   2.36692735e-03  5.13182173e-03  4.23237220e-03  1.33283667e-02\n",
      "  -1.81488981e-02 -2.87340614e-03 -1.16388073e-02 -1.00254511e-02\n",
      "   1.23115436e-02 -6.79287489e-03 -5.12726151e-03 -1.79421396e-03\n",
      "  -1.83975244e-02 -1.35594310e-02  9.17071953e-04 -1.15444658e-03\n",
      "  -6.28450379e-03 -1.33590680e-03 -9.51390371e-04  3.72347486e-03\n",
      "   4.00167898e-03 -1.93328933e-02 -1.38534964e-03  4.23451062e-03\n",
      "   1.16045280e-03 -7.19667551e-03  9.65106436e-03 -3.91851532e-03\n",
      "  -1.04021252e-02 -9.11072306e-04 -7.47654058e-03  1.25342650e-02\n",
      "   9.55368405e-03  8.80002531e-03  9.21955825e-03 -1.53063643e-02\n",
      "  -2.90081777e-03  7.09302601e-03  6.05584535e-03 -9.32789046e-03\n",
      "  -4.27706437e-03 -6.50105128e-03 -5.90858379e-03  6.78404656e-03\n",
      "   4.85167964e-03 -9.20719912e-03  1.92644620e-03  1.37693024e-02\n",
      "   2.52584868e-03  4.59970299e-03 -9.33121720e-03 -1.78309315e-03\n",
      "  -7.59191312e-03  8.29969966e-03 -1.28262483e-02 -4.43688405e-03\n",
      "  -1.15675800e-02 -8.46862602e-03  5.74488832e-03  6.43649894e-03\n",
      "   2.00672899e-02  9.40689212e-03  1.57031109e-02  1.71517713e-03\n",
      "  -1.58398226e-03  1.07930157e-02 -3.77316161e-05  1.34328687e-02\n",
      "  -1.67355614e-02 -2.59603316e-02  8.29811423e-03 -1.95476976e-02\n",
      "  -5.63723967e-03  4.92232453e-03  5.96334032e-03 -7.92791223e-03\n",
      "   7.83330308e-04 -8.68551685e-03  7.91699126e-03 -1.43628684e-02\n",
      "   1.09047396e-02  8.78870046e-03  1.31811005e-02  3.20265824e-03\n",
      "   6.36944348e-05 -6.49616743e-03 -8.36428913e-03  2.72061761e-03\n",
      "  -8.19221494e-03 -1.89127739e-02 -1.03639067e-02 -6.52967444e-03\n",
      "  -6.98289861e-03  1.27012818e-02  1.89008749e-03  2.78228460e-03\n",
      "  -3.52360555e-03  4.32195191e-03  1.88056165e-03  9.79933127e-03\n",
      "   1.36420488e-03  4.99682671e-04  7.35588603e-03  9.12383494e-03\n",
      "   1.13001145e-02  2.03118253e-02 -4.29228143e-03  1.30999837e-03\n",
      "  -6.80711849e-03 -1.31016624e-02  9.67902200e-03  1.03325859e-02\n",
      "  -9.66974693e-03 -1.32954026e-02  9.62794205e-03 -6.01767871e-03\n",
      "  -6.69934967e-03 -8.97247064e-03  1.07142360e-02  1.56374444e-03\n",
      "   8.81809434e-06 -1.48233079e-02 -8.34131452e-03 -1.00593801e-02\n",
      "   9.54563801e-03  1.00839737e-03 -1.09046507e-02  5.64140979e-04\n",
      "   2.15132449e-03 -2.04290857e-03 -8.98478371e-03  1.35723372e-03\n",
      "  -1.16662238e-02 -1.10321653e-02  5.42886096e-03 -7.28147151e-03\n",
      "  -3.06185845e-02  5.55687856e-03 -1.90500340e-02 -1.12514480e-02\n",
      "  -9.10509717e-03 -1.45571487e-02 -7.37606402e-03 -2.75166213e-02\n",
      "  -2.13406953e-03  6.38279642e-03 -1.19839548e-03 -4.61696008e-03\n",
      "  -3.08353764e-03  1.33503163e-02 -6.84845987e-04 -4.64196606e-04\n",
      "  -2.35937335e-02 -5.65370487e-03 -3.29398942e-03  1.53157147e-02\n",
      "  -1.10624025e-03 -3.23925343e-03 -8.35656049e-03  1.86194809e-02\n",
      "  -2.97201969e-03 -4.64546424e-03 -2.46452257e-04  1.37460872e-02\n",
      "   2.36752675e-03  1.30057395e-02 -2.07145076e-03  2.17892170e-02\n",
      "  -5.65690162e-03  3.32484826e-03  7.87964174e-03 -1.01360592e-02\n",
      "   1.39558482e-02  1.20631361e-02  2.50258490e-02 -5.85439320e-03\n",
      "  -3.16341917e-03  3.92257505e-03  6.76654622e-03 -4.81215712e-03\n",
      "  -5.93781996e-03 -3.80480718e-03  1.25127850e-02  3.74067570e-03\n",
      "  -6.28352850e-03  1.21773394e-02 -6.72229958e-03  4.12602856e-03\n",
      "   4.27747383e-03 -7.45874045e-03  9.34564397e-03  1.12232671e-02\n",
      "   7.33463133e-03  1.10300861e-02  1.15592013e-02 -6.84132556e-03\n",
      "  -2.64315743e-02  1.72205188e-02  2.43493572e-03  2.46181985e-04\n",
      "  -2.13746582e-02  1.03947245e-03 -1.59598715e-03 -2.78086966e-03\n",
      "  -8.79489906e-03 -2.62733732e-02  2.52389103e-02  1.21395549e-03\n",
      "   1.14473830e-02 -4.90274894e-04 -1.26392495e-02  1.00984264e-02\n",
      "   7.20305992e-03  1.21737479e-02  3.14532913e-04 -3.55280357e-03\n",
      "  -1.89665042e-02  3.92099862e-03 -1.20563515e-02  6.39725605e-03\n",
      "  -9.94049510e-03  1.23979825e-02  1.45748745e-03  6.28744486e-03\n",
      "   5.98654587e-03  2.32989290e-02 -1.15886571e-03 -7.79820650e-03\n",
      "   8.00084229e-03  5.82794897e-03 -1.99170340e-03  9.20692052e-03\n",
      "   1.09726945e-02 -2.23999639e-02 -9.68875719e-03 -6.03952039e-05]]\n",
      "acc: 0.099, loss: 2.303, lr: 1.0\n",
      "acc: 0.099, loss: 2.303, lr: 1.0\n",
      "epoch:0, acc: 0.887, loss: 0.391, lr: 0.7930214115781126\n",
      "test - epoch:0, acc: 0.883, loss: 0.395, lr: 0.7930214115781126\n",
      "epoch:1, acc: 0.907, loss: 0.324, lr: 0.6565988181221273\n",
      "test - epoch:1, acc: 0.902, loss: 0.336, lr: 0.6565988181221273\n",
      "epoch:2, acc: 0.916, loss: 0.302, lr: 0.5602240896358543\n",
      "test - epoch:2, acc: 0.907, loss: 0.318, lr: 0.5602240896358543\n",
      "epoch:3, acc: 0.918, loss: 0.289, lr: 0.4885197850512946\n",
      "test - epoch:3, acc: 0.910, loss: 0.310, lr: 0.4885197850512946\n",
      "epoch:4, acc: 0.920, loss: 0.281, lr: 0.43308791684711995\n",
      "test - epoch:4, acc: 0.911, loss: 0.305, lr: 0.43308791684711995\n",
      "epoch:5, acc: 0.923, loss: 0.274, lr: 0.3889537145079736\n",
      "test - epoch:5, acc: 0.912, loss: 0.301, lr: 0.3889537145079736\n",
      "epoch:6, acc: 0.925, loss: 0.269, lr: 0.35298270384751146\n",
      "test - epoch:6, acc: 0.913, loss: 0.298, lr: 0.35298270384751146\n",
      "epoch:7, acc: 0.926, loss: 0.265, lr: 0.32310177705977383\n",
      "test - epoch:7, acc: 0.913, loss: 0.296, lr: 0.32310177705977383\n",
      "epoch:8, acc: 0.927, loss: 0.261, lr: 0.29788501638367587\n",
      "test - epoch:8, acc: 0.914, loss: 0.294, lr: 0.29788501638367587\n",
      "epoch:9, acc: 0.928, loss: 0.258, lr: 0.27631942525559544\n",
      "test - epoch:9, acc: 0.914, loss: 0.292, lr: 0.27631942525559544\n"
     ]
    }
   ],
   "source": [
    "class Layers_Dense:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
    "        # self.biases = np.full((1, n_neurons), 0.001)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "        self.inputs = inputs\n",
    "\n",
    "    def backward(self, dvalues):\n",
    "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
    "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
    "        self.dinputs = np.dot(dvalues,self.weights.T)\n",
    "\n",
    "class Activation_ReLU:\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0,inputs)\n",
    "        self.inputs = inputs\n",
    "    \n",
    "    def backward(self, dvalues):\n",
    "        self.dinputs = dvalues.copy()\n",
    "        self.dinputs[self.inputs <= 0] = 0\n",
    "\n",
    "class customActivation:\n",
    "    def __init__(self, n_inputs):\n",
    "        self.weights = 0.01 * np.random.randn(1, n_inputs)\n",
    "        self.biases = 0.01 * np.random.randn(1, n_inputs)\n",
    "        print('k1:',self.weights, 'k0:', self.biases)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.multiply(inputs, self.weights) + self.biases\n",
    "        self.inputs = inputs\n",
    "    \n",
    "    def backward(self, dvalues):\n",
    "        self.dinputs = np.multiply(dvalues, self.weights)\n",
    "        self.dweights = np.mean(self.dinputs, axis=0, keepdims=True)\n",
    "        self.dbiases = np.mean(dvalues, axis=0, keepdims=True)\n",
    "\n",
    "class Activation_Softmax:\n",
    "    def forward(self, inputs):\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "        probalities = exp_values / np.sum(exp_values , axis = 1, keepdims=True)\n",
    "        self.output = probalities\n",
    "    \n",
    "    def backward(self, dvalues):\n",
    "        self.dinputs = np.empty_like(dvalues)\n",
    "        for index, (single_output, single_dvalues) in enumerate(zip(self.output,dvalues)):\n",
    "            single_output = single_output.reshape(-1, 1)\n",
    "            jacobian_matrix = np.diagflat(single_output) - np.dot(single_output, single_output.T)\n",
    "            self.dinputs[index] = np.dot(jacobian_matrix, single_dvalues)\n",
    "\n",
    "class Loss:\n",
    "    def calculate(self, output, y):\n",
    "        sample_losses = self.forward(output, y)\n",
    "        data_loss = np.mean(sample_losses)\n",
    "        return data_loss\n",
    "\n",
    "class Loss_CategorialCrossrntropy(Loss):\n",
    "    def forward(self, y_pred, y_true):\n",
    "        samples = len(y_pred)\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidence = y_pred_clipped[range(samples), y_true]\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correct_confidence = np.sum(y_pred_clipped * y_true, axis = 1)\n",
    "        negative_log_likelihoods = -np.log(correct_confidence)\n",
    "        return negative_log_likelihoods\n",
    "    \n",
    "    def backward(self,dvalues,y_true):\n",
    "        samples = len(dvalues)\n",
    "        lables = len(dvalues[0])\n",
    "        if len(y_true.shape) == 1:\n",
    "            y_true = np.eye(lables)[y_true]\n",
    "        self.dinputs = -y_true / dvalues\n",
    "        self.dinputs = self.dinputs / samples\n",
    "\n",
    "class Activation_Softmax_Loss_CategorialCrossrntropy():\n",
    "    def __init__(self):\n",
    "        self.activation = Activation_Softmax()\n",
    "        self.loss = Loss_CategorialCrossrntropy()\n",
    "\n",
    "    def forward(self, inputs, y_true):\n",
    "        self.activation.forward(inputs)\n",
    "        self.output = self.activation.output\n",
    "        return self.loss.calculate(self.output, y_true)\n",
    "\n",
    "    def backward(self, dvalues, y_true):\n",
    "        samples = len(dvalues)\n",
    "        if len(y_true.shape) == 2:\n",
    "            y_true = np.argmax(y_true, axis=1)\n",
    "        self.dinputs = dvalues.copy()\n",
    "        self.dinputs[range(samples), y_true] -=1\n",
    "        self.dinputs = self.dinputs / samples\n",
    "\n",
    "class Optimizer_SGD:\n",
    "    def __init__(self, learning_rate= 1.0, decay=0., momentum=0.):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iteration = 0\n",
    "        self.momentum = momentum\n",
    "\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * (1. / (1. + self.decay * self.iteration))\n",
    "    \n",
    "    def update_params(self, layer):\n",
    "        if self.momentum:\n",
    "            if not hasattr(layer, 'weight_momentums'):\n",
    "                layer.weight_momentums = np.zeros_like(layer.weights)\n",
    "                layer.bias_momentums = np.zeros_like(layer.biases)\n",
    "            weight_updates = self.momentum * layer.weight_momentums - self.current_learning_rate * layer.dweights\n",
    "            layer.weight_momentums = weight_updates\n",
    "            bias_updates = self.momentum * layer.bias_momentums - self.current_learning_rate * layer.dbiases\n",
    "            layer.bias_momentums = bias_updates\n",
    "        else:\n",
    "            weight_updates = -self.current_learning_rate * layer.dweights\n",
    "            bias_updates = -self.current_learning_rate * layer.dbiases\n",
    "\n",
    "        layer.weights += weight_updates\n",
    "        layer.biases += bias_updates\n",
    "    \n",
    "    def post_update_params(self):\n",
    "        self.iteration += 1\n",
    "\n",
    "\n",
    "dense1 = Layers_Dense(784, 392)\n",
    "activation1 = customActivation(392)\n",
    "dense2 = Layers_Dense(392, 10)\n",
    "loss_activation = Activation_Softmax_Loss_CategorialCrossrntropy()\n",
    "optimizer = Optimizer_SGD(decay=1e-3, momentum=0.9)  \n",
    "\n",
    "steps_train = x_train.to_numpy().shape[0] // BATCH_SIZE\n",
    "info = {'train_loss': [] , 'test_loss': [] , 'train_acc':[], 'test_acc': []}\n",
    "\n",
    "\n",
    "\n",
    "dense1.forward(x_train.to_numpy())\n",
    "activation1.forward(dense1.output)\n",
    "\n",
    "dense2.forward(activation1.output)\n",
    "loss = loss_activation.forward(dense2.output, y_train.to_numpy())\n",
    "predictions = np.argmax(loss_activation.output, axis=1)\n",
    "if len(y.shape) == 2:\n",
    "    y = np.argmax(y_train.to_numpy(), axis=1)\n",
    "accuracy = np.mean(predictions == y_train.to_numpy())\n",
    "info['train_loss'].append(loss)\n",
    "info['train_acc'].append(accuracy)\n",
    "print(f'acc: {accuracy:.3f}, ' + f'loss: {loss:.3f}, ' + f'lr: {optimizer.current_learning_rate}')\n",
    "\n",
    "dense1.forward(x_test.to_numpy())\n",
    "activation1.forward(dense1.output)\n",
    "\n",
    "dense2.forward(activation1.output)\n",
    "loss = loss_activation.forward(dense2.output, y_test.to_numpy())\n",
    "predictions = np.argmax(loss_activation.output, axis=1)\n",
    "if len(y.shape) == 2:\n",
    "    y = np.argmax(y_test.to_numpy(), axis=1)\n",
    "accuracy = np.mean(predictions == y_test.to_numpy())\n",
    "info['test_loss'].append(loss)\n",
    "info['test_acc'].append(accuracy)\n",
    "print(f'acc: {accuracy:.3f}, ' + f'loss: {loss:.3f}, ' +\n",
    "        f'lr: {optimizer.current_learning_rate}')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for step in range(steps_train):\n",
    "        x_batch = x_train[step*BATCH_SIZE:(step+1)*BATCH_SIZE]\n",
    "        y_batch = y_train[step*BATCH_SIZE:(step+1)*BATCH_SIZE]\n",
    "\n",
    "        dense1.forward(x_batch.to_numpy())\n",
    "        activation1.forward(dense1.output)\n",
    "\n",
    "        dense2.forward(activation1.output)\n",
    "        loss = loss_activation.forward(dense2.output, y_batch.to_numpy())\n",
    "\n",
    "        predictions = np.argmax(loss_activation.output, axis=1)\n",
    "        if len(y.shape) == 2:\n",
    "            y = np.argmax(y_batch.to_numpy(), axis=1)\n",
    "        accuracy = np.mean(predictions == y_batch.to_numpy())\n",
    "\n",
    "        # if not epoch % 100:\n",
    "        #     print(f'epoch:{epoch}, ' +\n",
    "        #         f'acc: {accuracy:.3f}, ' + f'loss: {loss:.3f}, ' +\n",
    "        #         f'lr: {optimizer.current_learning_rate}')\n",
    "\n",
    "        loss_activation.backward(loss_activation.output, y_batch.to_numpy())\n",
    "        dense2.backward(loss_activation.dinputs)\n",
    "        activation1.backward(dense2.dinputs)\n",
    "        dense1.backward(activation1.dinputs)\n",
    "\n",
    "        optimizer.pre_update_params()\n",
    "        optimizer.update_params(dense1)\n",
    "        optimizer.update_params(activation1)\n",
    "        optimizer.update_params(dense2)\n",
    "        optimizer.post_update_params()\n",
    "    \n",
    "    dense1.forward(x_train.to_numpy())\n",
    "    activation1.forward(dense1.output)\n",
    "\n",
    "    dense2.forward(activation1.output)\n",
    "    loss = loss_activation.forward(dense2.output, y_train.to_numpy())\n",
    "    predictions = np.argmax(loss_activation.output, axis=1)\n",
    "    if len(y.shape) == 2:\n",
    "        y = np.argmax(y_train.to_numpy(), axis=1)\n",
    "    accuracy = np.mean(predictions == y_train.to_numpy())\n",
    "    print(f'epoch:{epoch}, ' +\n",
    "          f'acc: {accuracy:.3f}, ' + f'loss: {loss:.3f}, ' +\n",
    "          f'lr: {optimizer.current_learning_rate}')\n",
    "    info['train_loss'].append(loss)\n",
    "    info['train_acc'].append(accuracy)\n",
    "\n",
    "    dense1.forward(x_test.to_numpy())\n",
    "    activation1.forward(dense1.output)\n",
    "\n",
    "    dense2.forward(activation1.output)\n",
    "    loss = loss_activation.forward(dense2.output, y_test.to_numpy())\n",
    "    predictions = np.argmax(loss_activation.output, axis=1)\n",
    "    if len(y.shape) == 2:\n",
    "        y = np.argmax(y_test.to_numpy(), axis=1)\n",
    "    accuracy = np.mean(predictions == y_test.to_numpy())\n",
    "    print(f'test - epoch:{epoch}, ' +\n",
    "          f'acc: {accuracy:.3f}, ' + f'loss: {loss:.3f}, ' +\n",
    "          f'lr: {optimizer.current_learning_rate}')\n",
    "    info['test_loss'].append(loss)\n",
    "    info['test_acc'].append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1998904f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2.3026631496008894, 0.39100470492480127, 0.3243307363094053, 0.30209641574662305, 0.2894283602464136, 0.28055652253669067, 0.27398558143316415, 0.2688088722171248, 0.26456065693630265, 0.2610264260320869, 0.25809095030399226]\n[0.09895833333333333, 0.8868154761904762, 0.9075, 0.9158928571428572, 0.9184821428571428, 0.920327380952381, 0.9230059523809524, 0.924970238095238, 0.9259821428571429, 0.9270238095238095, 0.9276785714285715]\n[2.302661118810443, 0.39484177874207144, 0.3355171007818289, 0.31849376700804666, 0.31017351284584566, 0.3048479281152066, 0.3010695851506112, 0.2981330810125274, 0.2957629672774805, 0.29386399213042097, 0.2923857024854099]\n[0.09916666666666667, 0.8826190476190476, 0.9019047619047619, 0.9069047619047619, 0.9103571428571429, 0.9107142857142857, 0.9119047619047619, 0.9130952380952381, 0.9133333333333333, 0.9138095238095238, 0.9136904761904762]\n"
     ]
    }
   ],
   "source": [
    "print(info['train_loss'])\n",
    "print(info['train_acc'])\n",
    "\n",
    "print(info['test_loss'])\n",
    "print(info['test_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faff8d12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "k1: [[-8.87301092e-03  5.22703529e-03 -1.07066000e-02  4.43866721e-03\n   2.40874552e-03 -6.45549871e-03  1.60086129e-02 -8.36490382e-03\n   3.94254707e-03  2.65726911e-03  1.65289856e-02 -1.41849664e-02\n  -7.83545133e-03 -2.50899743e-03 -1.35103990e-02  1.16982307e-02\n  -1.18361053e-02 -1.08316044e-02 -1.03938118e-02 -5.34363199e-03\n  -3.03443066e-03 -1.75412213e-02  7.14572763e-03  3.24980420e-03\n  -1.23598121e-02 -1.32288315e-02 -2.67987019e-03 -6.19851740e-03\n   4.01740946e-03  4.55678514e-03 -8.80586892e-03  2.49390457e-03\n  -2.52019780e-03  1.44167181e-02  3.64283456e-03 -1.35923008e-02\n   5.87206792e-03  1.28688819e-02 -7.15064049e-03  1.87523221e-02\n   5.65439886e-03  1.25691784e-02 -1.94058557e-02 -1.63533730e-02\n  -2.20100146e-02 -3.45482266e-04 -1.27910150e-02 -1.35432817e-02\n   1.84377893e-02  1.74482590e-03 -7.55802984e-04  2.38354692e-03\n   2.38544726e-03 -2.28157604e-02  1.57698667e-02  2.31688374e-02\n   9.22203797e-03  4.19426187e-03  2.75890972e-03 -1.22240651e-02\n  -7.14012976e-04 -8.11526978e-03 -1.04808829e-02  3.22344110e-03\n   1.42498593e-02  2.60646296e-02  4.81087549e-03 -1.74070583e-02\n  -1.51642850e-02  3.03181425e-03 -7.47068362e-03 -1.97365318e-03\n   1.60764847e-02 -8.07653582e-03  6.37077889e-03 -2.24356509e-02\n   1.13383478e-02  7.60802175e-03  7.66013632e-03  1.19507662e-02\n   9.08121501e-03 -9.31228157e-03 -1.35094653e-02 -1.08923436e-02\n  -9.66884816e-03  1.61479081e-02  7.39783421e-03 -8.17664142e-03\n   7.13400526e-03  9.65691486e-04  1.91489700e-03 -3.02533593e-03\n   1.72773684e-02  3.95004650e-04  4.18664282e-03 -2.26781587e-03\n   1.40492243e-02  9.39134873e-03  1.01646972e-02  6.34417251e-03\n   5.97488645e-03  1.96408908e-03  1.70836295e-03 -1.52194788e-02\n  -1.12454658e-03 -5.18116677e-03 -6.07560796e-03  4.04302648e-06\n   7.53938780e-03 -2.82321926e-04 -6.91180687e-04  1.09673884e-02\n   5.22856729e-03  2.01594822e-02  1.25155465e-02 -1.07983232e-02\n   2.02217625e-03 -1.22310216e-03  4.65819546e-04  1.19731223e-02\n   9.74189511e-03 -9.42248701e-03  1.08620915e-02 -4.99379248e-03\n  -4.81854032e-03  2.97375648e-03 -1.04957735e-02 -2.70905883e-02\n  -1.58036135e-02 -1.14027464e-02  2.74742820e-03  1.13956712e-02\n  -2.62110543e-03  6.31972070e-03  1.19607558e-02 -2.56919789e-03\n   5.25897455e-03  1.07731411e-02  9.87197760e-03 -2.74937668e-03\n   1.04598973e-02 -1.44244194e-02  4.06765731e-03 -1.65865815e-03\n   6.32499976e-03 -2.21239351e-02 -1.26422258e-02  7.22974640e-03\n  -2.31106608e-02  1.19873086e-03 -1.33426689e-02 -8.08222945e-03\n  -1.45997225e-03 -2.43151529e-03  8.02925332e-03  1.42836258e-03\n  -9.92177297e-03  7.72590412e-03 -2.82666798e-03  1.03231484e-02\n  -7.06349059e-03 -3.85262153e-03 -4.83249820e-03  1.14495560e-02\n  -4.08065936e-03  3.17739333e-03  1.76400837e-02 -4.48927142e-03\n   5.02630959e-03  8.92687926e-03  8.48585015e-03 -1.20623353e-02\n   3.92208495e-03  3.25664282e-03 -1.31187773e-03 -6.24608441e-04\n  -7.58968316e-03 -7.79382902e-03  1.89765977e-04  1.22101911e-03\n   1.35428650e-02 -1.05252173e-03  3.17851629e-03  9.55975354e-03\n   6.59325006e-03 -1.00302789e-02  6.97588814e-03 -1.25102358e-02\n  -1.32369043e-02 -8.01744965e-03  2.20587470e-02  3.03949876e-03\n   4.60265879e-03 -2.32905446e-04 -1.97702872e-03  5.09489564e-03\n  -3.71078039e-03 -1.02595771e-03  5.74517030e-03 -5.31864486e-04\n   8.69676509e-03 -2.48104066e-03 -1.45839931e-02 -1.78197104e-03\n  -3.13191655e-03  8.68846471e-03 -3.86288323e-03  5.17444926e-03\n  -6.01255961e-03  2.13890058e-02 -8.62971478e-03 -7.83947453e-04\n   5.09978485e-04  4.99899587e-03 -7.17290149e-03 -1.24972206e-02\n   3.60042759e-03  1.03391911e-02  7.68271830e-03  1.11312626e-02\n   5.71338323e-03  1.28890629e-02  7.55615197e-03  4.43275747e-03\n  -7.72293523e-03  7.32397926e-03 -1.81772959e-02 -3.08755104e-03\n   5.81556816e-03  3.83554895e-03 -5.36072934e-03 -1.26107578e-02\n  -8.65637163e-03 -9.15345291e-03 -2.88903439e-02 -7.93741859e-03\n   1.23709931e-02  5.28996085e-03 -3.39834415e-03  4.65057833e-04\n   1.98270139e-03 -1.04188021e-02 -9.08331759e-03 -5.86543528e-03\n   6.32016397e-03  5.12696270e-03  1.42246283e-02  1.79563565e-03\n  -1.81509336e-04 -2.86656469e-03  3.08324291e-03 -7.66219402e-03\n   6.80822956e-03  1.65030041e-02 -1.77509211e-02  1.41619495e-02\n  -7.15313651e-03 -5.50901189e-03  5.62973151e-04  1.73916757e-02\n  -6.49337947e-03 -1.19236602e-02 -9.90040525e-03  3.21151744e-03\n   2.10435841e-02  1.07011062e-02 -1.28924541e-02 -1.32598699e-02\n   5.98392126e-03  8.64547218e-03 -5.14085278e-03  5.58194414e-04\n   3.89139581e-03 -1.17492629e-03 -9.13877709e-04 -2.48270241e-03\n  -4.39944162e-03  1.57245614e-02 -1.10734435e-02  1.69517673e-02\n   3.13279285e-03  7.99424758e-03 -1.70249343e-03  1.44424010e-02\n   1.68740236e-03 -1.12269535e-02 -1.32803739e-02  7.71495138e-04\n   8.80263886e-03 -7.81159874e-03 -1.89340331e-03  8.07773360e-03\n  -5.26316683e-03  1.00077609e-02 -8.79101850e-03 -2.24501820e-03\n   7.16652156e-03  1.40487853e-02  1.27631561e-02  1.20044129e-04\n   1.18461137e-02  3.63810135e-03 -1.85987727e-02  1.07701655e-02\n  -7.85429701e-03 -1.02220509e-02 -4.34595404e-03  7.99653813e-03\n  -3.44166710e-03  3.80611182e-03  2.16094552e-02 -5.61890625e-03\n  -6.92296522e-03 -1.98347667e-02 -1.02295583e-02  1.77223910e-02\n  -1.83475856e-02  1.48584993e-02 -7.39765165e-03  7.62298111e-03\n  -5.62095752e-04  8.09150488e-03 -2.13601791e-02 -5.95033387e-03\n   1.86187039e-02  6.48313901e-03  1.88754074e-02  3.27351610e-04\n   1.82229926e-02 -8.09980733e-03 -1.20084385e-03  7.18728326e-03\n   1.12602862e-02 -4.43520537e-03 -4.60830703e-03  2.60874539e-02\n  -1.30897884e-02 -6.96292034e-03 -1.79166333e-03  3.01932061e-03\n  -1.30161496e-02  6.01044871e-03 -6.81853211e-03  4.13596871e-03\n  -1.50047980e-02 -1.10757692e-02  2.56668579e-03  5.13054723e-03\n  -1.35211169e-02  5.57831605e-03 -7.12687371e-03 -8.27548607e-03\n  -1.06338340e-02 -1.69840125e-02 -5.62845303e-03 -4.03969792e-03\n  -1.25065502e-02  4.00810139e-03 -1.62943585e-03 -1.89368817e-02\n   1.14523030e-02 -9.59282307e-03  5.62180477e-03  5.40414579e-03\n  -1.40248994e-03  1.55942434e-02  1.26457861e-02  6.26921826e-03\n  -5.06986237e-03 -2.62200062e-02 -9.00168379e-03 -1.36513621e-02\n   1.88105995e-03  7.55052897e-03  1.92513002e-03 -1.01553158e-02\n   1.09281736e-02  1.41505321e-02  5.08185821e-03 -4.25759652e-03\n  -1.06330342e-02 -5.41220435e-03  6.36417776e-03  2.91047306e-03\n  -4.44376835e-03 -2.33839439e-03  1.67772000e-02  2.28256194e-02\n  -1.40436226e-02 -4.95764767e-03 -1.55164719e-02 -1.39319781e-02]] k0: [[ 3.35914019e-03  2.02442677e-03  6.81004754e-03  6.79551075e-03\n  -3.09786409e-03  5.43960996e-03  4.11862701e-03 -7.34387487e-04\n  -3.89057440e-03  4.34916002e-04 -1.56377924e-03 -1.32564953e-02\n  -6.87195813e-03 -5.11442701e-03 -1.52147773e-03  2.91017579e-03\n  -2.37839542e-03 -7.24401049e-04 -1.16507776e-03  2.91071504e-03\n   1.57128682e-03 -7.28368795e-03  6.04729204e-03 -4.57887932e-03\n  -2.63014901e-03 -4.25248298e-03 -8.45683801e-03 -5.59116484e-03\n   3.54558577e-03 -3.06748002e-03 -3.53343834e-03  1.62071835e-03\n   8.29931371e-03 -8.37925932e-03 -9.14562705e-03  1.66741485e-02\n  -9.04632129e-04  6.62101762e-03 -1.43524518e-03  1.33765178e-02\n   9.91914776e-03  2.36993547e-03  2.02080695e-04  5.68857565e-03\n  -2.94821241e-02 -8.20420151e-03  1.17219699e-02 -1.33008108e-02\n  -1.36080029e-02  6.07404602e-03 -8.89430083e-04  2.47228059e-06\n  -2.10465620e-03  4.77548047e-02 -3.75767817e-03 -5.85870744e-03\n   8.26040926e-03  4.43474431e-03 -3.18773912e-04 -9.44505346e-03\n   3.08575205e-03 -2.87187872e-03  1.45942638e-02  2.34506643e-03\n   9.00064984e-03  8.54590915e-02  1.07668268e-02  6.17339003e-03\n   2.10318405e-03  2.16869694e-04  1.13441434e-03  9.48638282e-04\n   8.90550213e-03  2.39373250e-02 -2.71629801e-03  2.63006422e-02\n   2.28272497e-03  5.09671232e-03  1.78913916e-03 -6.07825659e-03\n   5.86522691e-06  1.13391985e-04 -1.28624296e-03  9.69212561e-03\n  -5.06082228e-03 -1.30680382e-02  1.41532998e-03 -6.02515716e-03\n   4.54654401e-03 -1.06055315e-02  3.86427960e-03  1.02415412e-03\n  -5.14696242e-03  2.19431829e-03  2.21620787e-03 -9.14857030e-03\n   1.92605372e-02 -4.05985194e-04 -2.32791245e-04 -3.43849324e-03\n   6.95232983e-03  1.43274576e-03  4.91792578e-04  1.21681841e-02\n   2.23664330e-03  4.05337763e-03 -8.26513725e-03  7.03673422e-03\n   5.40980584e-03  4.89009000e-03  1.04964753e-03  1.06192920e-02\n   8.89173152e-03  1.38876981e-02  2.39811793e-03 -2.32688185e-03\n  -7.32522952e-03 -6.94618215e-03  4.39946683e-03 -2.45759109e-03\n  -7.19112281e-03 -1.81632002e-02 -3.00602597e-03  4.36318717e-03\n   4.40134106e-03  4.81495931e-03 -1.29731299e-02 -7.81133461e-02\n   1.16892990e-02  1.67063914e-03 -1.81930456e-03 -2.00662022e-03\n  -1.00138192e-02 -6.68736837e-04  9.00660415e-03 -1.44312967e-03\n   5.73622332e-03 -4.41731086e-03 -3.27779478e-03 -5.17143731e-03\n  -5.11596213e-03 -4.27991821e-03  7.12706005e-03  8.05968968e-03\n   2.70403991e-03 -9.18233122e-04  2.53618562e-03 -1.14491981e-03\n  -6.85198697e-03 -3.33669672e-03 -5.41606464e-03 -4.31100485e-03\n  -8.21223084e-03 -3.16318953e-03 -1.06862217e-02  5.20478637e-03\n   3.37060457e-04  4.53386054e-03  2.73498962e-03  9.44739544e-03\n  -1.14928147e-02 -1.51775174e-03 -6.69274874e-03 -5.24672905e-03\n   6.97083571e-03 -4.40307766e-03 -1.10302261e-02 -9.70468817e-04\n  -1.05908878e-02 -8.14618689e-03  1.74695833e-03  2.19359812e-03\n  -3.74849592e-03 -1.05237033e-03 -5.20755297e-04  2.11671714e-03\n   1.72446218e-03 -1.30210647e-02 -7.15366391e-04  2.43141341e-03\n  -1.13180978e-04 -4.13712487e-03  5.79552879e-03 -2.67402593e-03\n  -6.21647371e-03  1.86058440e-03 -5.32055621e-03 -2.01983417e-05\n   7.08753564e-03  5.88183995e-03 -3.09506907e-03 -8.99074248e-03\n  -1.71941655e-03  3.85093990e-03  3.86479793e-03 -5.69086946e-03\n  -2.83863647e-03 -3.47492164e-03 -3.62723875e-03  4.18613659e-03\n   4.29060048e-03 -5.77293737e-03  8.48934707e-04  8.31759598e-03\n   1.72705721e-03  3.73623754e-03 -5.93099637e-03 -9.37027993e-04\n  -4.11900356e-03  1.68569703e-02 -8.42976965e-03 -2.54643846e-03\n  -6.97884549e-03 -5.08949142e-03  4.65419415e-03  4.68889328e-03\n   1.21454149e-02  7.69146979e-03  1.03563895e-02 -7.48842876e-04\n  -1.07632401e-03  1.12004394e-02 -1.54498566e-06  7.52128180e-03\n  -8.07540848e-03 -1.53412957e-02  6.50185724e-03 -1.14563583e-02\n  -2.90800267e-03  2.33830701e-03  3.40390664e-03 -8.81198618e-03\n  -4.59004325e-04 -5.97546814e-03  8.87864489e-02 -7.91304727e-03\n   7.22573323e-03  4.84800990e-03  7.85033191e-03  2.03398407e-03\n   4.94493252e-05 -5.91100654e-03 -4.21504895e-03  6.89987286e-04\n  -4.51588901e-03 -1.19631131e-02 -4.14444411e-03 -3.92087679e-03\n  -4.27992662e-03  7.51357372e-03  1.08385427e-03  7.66825344e-04\n  -2.28343955e-03  3.87095083e-03 -1.34119868e-02  7.32344309e-03\n   3.86756402e-05 -1.29964541e-04  4.01158387e-03  1.12171476e-02\n   6.91451143e-03  1.06486947e-02 -2.95516583e-03  1.03217241e-03\n  -1.70630911e-02 -7.92927206e-03  3.64803477e-03  6.62999143e-03\n  -6.11875644e-03 -7.28185779e-03  5.35951184e-03 -3.47367141e-03\n  -3.79582761e-03 -5.41902325e-03  6.20495460e-03  8.71212326e-04\n  -4.05926827e-04 -1.50764655e-02 -7.56332714e-03 -1.85575351e-02\n   5.81895002e-03  1.42201805e-03 -6.29852252e-03  3.31510811e-03\n   1.25328531e-03 -2.03277112e-05 -9.07690739e-03  7.00588853e-04\n  -7.76685958e-03 -6.33860949e-03  3.26732710e-03 -3.41259466e-03\n  -1.74779480e-02  2.16393773e-03 -1.19624814e-02 -6.60369954e-03\n  -5.08536734e-03 -1.06567853e-02 -3.36623319e-03 -1.61355323e-02\n   5.74802454e-04  3.46471504e-03  1.36090488e-02 -6.92015012e-03\n  -1.24566208e-03  1.01451467e-02 -3.52047734e-04 -1.31725736e-03\n  -1.41955509e-02 -3.55253541e-03 -4.92156942e-02  9.08813958e-03\n  -2.39497152e-04 -2.48276604e-02 -4.09882678e-03  2.97214769e-02\n  -1.62110993e-02 -1.73869335e-02 -2.85123002e-05  8.77662059e-03\n   1.60308565e-03  6.99973150e-03 -2.38586969e-02  1.32437061e-02\n  -3.75360744e-02  1.95626367e-03 -1.57297701e-02 -5.77373220e-03\n   1.39062285e-02  5.74624633e-03  1.44417795e-02 -3.16863507e-03\n  -4.97012049e-03  2.91152219e-03  3.89462999e-03  3.57492900e-03\n  -8.86232521e-03 -9.75527737e-04  7.27338068e-03  2.21244861e-03\n  -2.50981032e-03  8.14581355e-03 -4.14148252e-03  2.84589963e-03\n   6.52407273e-03 -6.50036684e-03  5.80585396e-03  6.46937769e-03\n   6.47317543e-03  6.07905670e-03  7.51420255e-03 -4.85083690e-03\n  -1.74006026e-02  2.35090972e-02  9.73425688e-04 -7.95126645e-05\n  -1.83877530e-02  3.48354333e-04 -6.26605879e-04 -1.14799228e-02\n  -3.77850160e-03 -1.90769898e-02  1.53033463e-02  6.56078110e-04\n   6.82798123e-03  1.01335343e-02 -8.72773392e-03  5.59491496e-03\n   4.10627705e-03  5.74595848e-02 -3.41573680e-04 -3.76302549e-03\n  -1.10646689e-02  2.86692711e-03 -7.25243421e-03  4.33241236e-03\n  -5.93952954e-03  9.34730211e-03  9.31108443e-04  3.46156345e-03\n   4.45601121e-03  1.43877544e-02 -1.91690304e-04 -4.60277078e-03\n   4.44987095e-03  3.18250687e-03 -2.43112950e-03  4.53333994e-02\n   4.93905895e-03 -1.34328280e-02 -6.59897669e-03  6.63224254e-03]]\n"
     ]
    }
   ],
   "source": [
    "print('k1:',activation1.weights, 'k0:', activation1.biases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2b490ad",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fcab00accc0>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 372.103125 248.518125\" width=\"372.103125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-05-26T16:05:40.907958</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.4.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 372.103125 248.518125 \nL 372.103125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 224.64 \nL 364.903125 224.64 \nL 364.903125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m1c15866b4a\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.321307\" xlink:href=\"#m1c15866b4a\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(42.140057 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"106.194034\" xlink:href=\"#m1c15866b4a\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2 -->\n      <g transform=\"translate(103.012784 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"167.066761\" xlink:href=\"#m1c15866b4a\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4 -->\n      <g transform=\"translate(163.885511 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" id=\"DejaVuSans-34\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"227.939489\" xlink:href=\"#m1c15866b4a\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6 -->\n      <g transform=\"translate(224.758239 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" id=\"DejaVuSans-36\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"288.812216\" xlink:href=\"#m1c15866b4a\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 8 -->\n      <g transform=\"translate(285.630966 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" id=\"DejaVuSans-38\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"349.684943\" xlink:href=\"#m1c15866b4a\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 10 -->\n      <g transform=\"translate(343.322443 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"mf5114e4bc1\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mf5114e4bc1\" y=\"223.632944\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.0 -->\n      <g transform=\"translate(7.2 227.432163)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" id=\"DejaVuSans-2e\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mf5114e4bc1\" y=\"178.782852\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.5 -->\n      <g transform=\"translate(7.2 182.582071)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" id=\"DejaVuSans-35\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mf5114e4bc1\" y=\"133.93276\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 1.0 -->\n      <g transform=\"translate(7.2 137.731979)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mf5114e4bc1\" y=\"89.082668\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 1.5 -->\n      <g transform=\"translate(7.2 92.881887)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mf5114e4bc1\" y=\"44.232577\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 2.0 -->\n      <g transform=\"translate(7.2 48.031795)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_12\">\n    <path clip-path=\"url(#p646f1651e1)\" d=\"M 45.321307 17.083636 \nL 75.75767 188.55975 \nL 106.194034 194.540418 \nL 136.630398 196.53484 \nL 167.066761 197.671167 \nL 197.503125 198.466973 \nL 227.939489 199.056387 \nL 258.375852 199.520739 \nL 288.812216 199.901805 \nL 319.24858 200.218826 \nL 349.684943 200.482139 \n\" style=\"fill:none;stroke:#ff0000;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_13\">\n    <path clip-path=\"url(#p646f1651e1)\" d=\"M 45.321307 17.083819 \nL 75.75767 188.215564 \nL 106.194034 193.536999 \nL 136.630398 195.063995 \nL 167.066761 195.810323 \nL 197.503125 196.288029 \nL 227.939489 196.626947 \nL 258.375852 196.890352 \nL 288.812216 197.102952 \nL 319.24858 197.27329 \nL 349.684943 197.405893 \n\" style=\"fill:none;stroke:#008000;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_14\">\n    <path clip-path=\"url(#p646f1651e1)\" d=\"M 45.321307 214.756364 \nL 75.75767 144.085433 \nL 106.194034 142.230027 \nL 136.630398 141.477187 \nL 167.066761 141.244927 \nL 197.503125 141.079409 \nL 227.939489 140.839141 \nL 258.375852 140.662944 \nL 288.812216 140.572176 \nL 319.24858 140.478738 \nL 349.684943 140.420006 \n\" style=\"fill:none;stroke:#ff0000;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_15\">\n    <path clip-path=\"url(#p646f1651e1)\" d=\"M 45.321307 214.737676 \nL 75.75767 144.461853 \nL 106.194034 142.731921 \nL 136.630398 142.28342 \nL 167.066761 141.973741 \nL 197.503125 141.941705 \nL 227.939489 141.834919 \nL 258.375852 141.728134 \nL 288.812216 141.706776 \nL 319.24858 141.664062 \nL 349.684943 141.674741 \n\" style=\"fill:none;stroke:#008000;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 224.64 \nL 30.103125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 364.903125 224.64 \nL 364.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 224.64 \nL 364.903125 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 364.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"line2d_16\">\n     <path d=\"M 39.103125 20.298437 \nL 59.103125 20.298437 \n\" style=\"fill:none;stroke:#ff0000;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_17\"/>\n    <g id=\"text_12\">\n     <!-- train_loss -->\n     <g transform=\"translate(67.103125 23.798437)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" id=\"DejaVuSans-74\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" id=\"DejaVuSans-72\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" id=\"DejaVuSans-61\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" id=\"DejaVuSans-69\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" id=\"DejaVuSans-6e\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 3263 -1063 \nL 3263 -1509 \nL -63 -1509 \nL -63 -1063 \nL 3263 -1063 \nz\n\" id=\"DejaVuSans-5f\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" id=\"DejaVuSans-6c\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" id=\"DejaVuSans-6f\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" id=\"DejaVuSans-73\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"232.763672\" xlink:href=\"#DejaVuSans-5f\"/>\n      <use x=\"282.763672\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"310.546875\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"371.728516\" xlink:href=\"#DejaVuSans-73\"/>\n      <use x=\"423.828125\" xlink:href=\"#DejaVuSans-73\"/>\n     </g>\n    </g>\n    <g id=\"line2d_18\">\n     <path d=\"M 39.103125 35.254687 \nL 59.103125 35.254687 \n\" style=\"fill:none;stroke:#008000;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_19\"/>\n    <g id=\"text_13\">\n     <!-- test_loss -->\n     <g transform=\"translate(67.103125 38.754687)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" id=\"DejaVuSans-65\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"100.732422\" xlink:href=\"#DejaVuSans-73\"/>\n      <use x=\"152.832031\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"192.041016\" xlink:href=\"#DejaVuSans-5f\"/>\n      <use x=\"242.041016\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"269.824219\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"331.005859\" xlink:href=\"#DejaVuSans-73\"/>\n      <use x=\"383.105469\" xlink:href=\"#DejaVuSans-73\"/>\n     </g>\n    </g>\n    <g id=\"line2d_20\">\n     <path d=\"M 39.103125 50.210937 \nL 59.103125 50.210937 \n\" style=\"fill:none;stroke:#ff0000;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_21\"/>\n    <g id=\"text_14\">\n     <!-- train_acc -->\n     <g transform=\"translate(67.103125 53.710937)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" id=\"DejaVuSans-63\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-6e\"/>\n      <use x=\"232.763672\" xlink:href=\"#DejaVuSans-5f\"/>\n      <use x=\"282.763672\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"344.042969\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"399.023438\" xlink:href=\"#DejaVuSans-63\"/>\n     </g>\n    </g>\n    <g id=\"line2d_22\">\n     <path d=\"M 39.103125 65.167187 \nL 59.103125 65.167187 \n\" style=\"fill:none;stroke:#008000;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_23\"/>\n    <g id=\"text_15\">\n     <!-- test_acc -->\n     <g transform=\"translate(67.103125 68.667187)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"100.732422\" xlink:href=\"#DejaVuSans-73\"/>\n      <use x=\"152.832031\" xlink:href=\"#DejaVuSans-74\"/>\n      <use x=\"192.041016\" xlink:href=\"#DejaVuSans-5f\"/>\n      <use x=\"242.041016\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"303.320312\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"358.300781\" xlink:href=\"#DejaVuSans-63\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p646f1651e1\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"30.103125\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.plot(range(len(info['train_loss'])), info['train_loss'], '--r', label='train_loss')\n",
    "plt.plot(range(len(info['test_loss'])), info['test_loss'], color='green', label='test_loss')\n",
    "plt.plot(range(len(info['train_acc'])), info['train_acc'], '--r', label='train_acc')\n",
    "plt.plot(range(len(info['test_acc'])), info['test_acc'], color='green', label='test_acc')\n",
    "plt.legend(loc='upper left', frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python370jvsc74a57bd0e3b4d936c1514ec141342f010bcac70b16dfd15e06165731f7bf5de209b5c7b2",
   "display_name": "Python 3.7.0 64-bit ('env': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}